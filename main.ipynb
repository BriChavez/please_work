{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pandas, numpy, imports and reads the csv files \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "albums_file = \"./data/spotify_albums.csv\"\n",
    "artists_file = \"./data/spotify_artists.csv\"\n",
    "tracks_file = \"./data/spotify_tracks.csv\"\n",
    "albums = pd.read_csv(albums_file, header=0)\n",
    "artists = pd.read_csv(artists_file, header=0)\n",
    "tracks = pd.read_csv(tracks_file, header=0)\n",
    "# hello!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For each dataset, profile the data using head(), tail(), and .shape. Write a comment for each one, briefly explaining what this technique does, and what the output you got tells you about the dataset. '''\n",
    "\n",
    "# uses .head() to show the first (n) rows are at the beginning of each column\n",
    "albums_head = albums.head()\n",
    "artists_head = artists.head()\n",
    "tracks_head = tracks.head()\n",
    "print(albums_head, artists_head, tracks_head)\n",
    "\n",
    "# uses .tail() to show the last (n) rows are at the end of each column. print the result\n",
    "albums_tail = albums.tail()\n",
    "artists_tail = artists.tail()\n",
    "tracks_tail = tracks.tail()\n",
    "print(albums_tail, artists_tail, tracks_tail)\n",
    "\n",
    "# uses .shape to show how many rows and columns are in each dataset. print the result.\n",
    "albums_shape = albums.shape\n",
    "artists_shape = artists.shape\n",
    "tracks_shape = tracks.shape\n",
    "print(tracks_shape)\n",
    "print(albums_shape, artists_shape, tracks_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # For Artists:\n",
    "# # Write a map() function to replace the empty list ([]) entries in the genres column with NaNs (but don't alter the list entries in genres that contain values!)\n",
    "\n",
    "# artists.fillna('NaN')\n",
    "\n",
    "def map_na (value):\n",
    "    if value =='[]':\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "artists['genres']= artists.genres.map(map_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For Albums, use .loc to show just rows 10-20 of the 'name' and 'release_date' columns '''\n",
    "\n",
    "# shows the values in rows 10-20 in columns name and release_date\n",
    "print(albums.loc[10:20, ['name', 'release_date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Clean and normalize each dataset: \"\"\"\n",
    "''' remove duplicates from dataset '''\n",
    "\n",
    "# # determines if any duplicates are in the data set\n",
    "dupe_albums = albums.duplicated().any()\n",
    "dupe_artists = artists.duplicated().any()\n",
    "dupe_tracks = tracks.duplicated().any()\n",
    "print(dupe_albums, dupe_artists, dupe_tracks)\n",
    "\n",
    "\n",
    "# # # drops duplicates\n",
    "albums = albums.drop_duplicates()\n",
    "artists = artists.drop_duplicates()\n",
    "tracks = tracks.drop_duplicates()\n",
    "\n",
    "\n",
    "# # retest to confirm that the dupes did in fact, drop\n",
    "dupe_albums = albums.duplicated().any()\n",
    "dupe_artists = artists.duplicated().any()\n",
    "dupe_tracks = tracks.duplicated().any()\n",
    "print(dupe_albums, dupe_artists, dupe_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For Tracks: \"\"\"\n",
    "\"\"\"  Print the names of the columns in Tracks  \"\"\"\n",
    "# prints the names of columns in the tracks data folder\n",
    "print(tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" drop the lyrics column \"\"\"\n",
    "# find the index number of the lyrics column\n",
    "tracks.drop('lyrics', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print the names of the Tracks columns again, to show that the 'lyrics' column has been dropped\"\"\"\n",
    "# prints names in tracks columns\n",
    "print(tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Using Pandas, perform the following joins, choosing the join type that you think is appropriate. Make a comment in your code file on why you chose that join type \"\"\"\n",
    "\"\"\"# Join artists and albums on the artist ID\"\"\"\n",
    "# merges artists and albums on ID. chose this one because they had it in common and inner merge seemed like the right way\n",
    "artists_albums = pd.merge(artists, albums, how='inner', left_on='id', right_on='artist_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print the head() and shape of the resulting DataFrame \"\"\"\n",
    "artists_albums_head = artists_albums.head()\n",
    "artists_album_shape = artists_albums.shape\n",
    "print(artists_albums_head, artists_album_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Join albums and tracks on the album ID\"\"\"\n",
    "# checks for columns in common fieldsprint(albums.columns)\n",
    "print(tracks.columns)\n",
    "print(albums.columns)\n",
    "\n",
    "# renames artist_id column to artists_id\n",
    "albums.rename(columns = {'artist_id':'artists_id'}, inplace = True)\n",
    "\n",
    "# joins albums and tracks on album ID using the left merge to have all the album information even if the tracks arent on the list\n",
    "artists_albums = pd.merge(artists, albums, how='left', left_on='id', right_on='artist_id')\n",
    "\n",
    "# checks my work\n",
    "print(albums_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print the head() and shape of the resulting DataFrame \"\"\"\n",
    "albums_tracks_head = albums_tracks.head()\n",
    "albums_tracks_shape = albums_tracks.shape\n",
    "print(albums_tracks_head, albums_tracks_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use the Pandas to calculate some statistics on the data, and print the results:\"\"\"\n",
    "artists_data = artists.describe()\n",
    "albums_data = albums.describe()\n",
    "tracks_data =albums.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Which artists appear the most times in the Artists data?\"\"\"\n",
    "# print(artists.columns)\n",
    "# print(artists.groupby(\"name\").max())\n",
    "artists['name'].value_counts()\n",
    "artists['name'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Which artists have the highest 'artist_popularity' rankings? (list the top ten in descending order)\"\"\"\n",
    "# finds artists by popularity, reverses the list and then returns the top ten\n",
    "coolness = artists.groupby('artist_popularity')['name'].value_counts()\n",
    "coolness = coolness[::-1]\n",
    "print(coolness.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Point: How many albums came out in each year? (Notice that the values in the release_date column of Albums is in the format yyyy-mm-dd)\n",
    "artists_albums['release_year'] = pd.DatetimeIndex(artists_albums['release_date']).year\n",
    "print(artists_albums.release_year.value_counts())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
